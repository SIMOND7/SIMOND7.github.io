---
# 기본 설정값
layout: single
toc: true
toc_sticky : true
toc_label : 목차
toc_icon: "fas fa-book-reader"
author_profile: false
search: true

# 제목, 카테고리, 태그
title:  "[Global_Data_Issue] 2023년 3월"
categories: "Global_Data_Issue"
tag: [Big Data, AI]
---

# 머리말
<div class="notice--info">
<h4>"인더스트리 4.0 인간과 기계의 상호보완이 결정할 것"<br/><br/>
Henning Kagermann / 마이클 포터</h4>
</div>
<br/>

# 중국판gpt
Open AI사의 Chat GPT가 출시 2개월 만에 이용자수 1억 명을 달성하며 AI에 대한 열기와 경쟁이 세계적으로 불붙었다.<br/>
중국에서도 지난 2월 푸단대학교 Qiu Zipeng 교수 팀이 중국 최초의 대규모 대화형 언어 모델 "중국판 Chat GPT" **MOSS**를 공개했다.<br/>
상하이 인공지능 연구소의 지원을 받아 제작된 MOSS는 인간의 의도를 이해하고 대화하는 모델이다.<br/>
하지만 출시와 동시에 접속자가 몰려 서버가 폭주하는 사태가 있었으며 서버 안정성이 부족한 것이 바로 드러났다.
또한 MOSS는 수백억 개의 매개변수가 있는 자체 개발 모델을 사용했으며 Chat GPT-3.5가 1750억개의 매개변수를 사용한 점을 비교 했을 때, 훨씬 적은 매개변수를 사용했다. MOSS에게 상하이의 인공지능 산업을 발전시키는 방법을 중국어로 질문해 보았더니 다음과 같이 대답했다.<br/>

![moss]({{site.url}}\images\2023-03-22-gdata33\moss.png)


- 질문 : 상하이에서 인공지능 산업을 더 발전시키는 방법은 무엇인가?

- MOSS : 상하이는 다음과 같은 방식으로 AI 산업을 더 잘 발전시킬 수 있다고 생각합니다.<br/> 1. 인공 지능 분야의 연구 개발을 강화하고 학술 연구를 지원하며 과학 발전을 촉진해야 합니다. <br/>2. 산업 자원의 통합을 강화하고 인공 지능 산업의 발전을 촉진해야 합니다. <br/>3. 인공지능 관련 제품 연구개발 강화 및 제품 경쟁력을 향상시켜야 합니다. <br/>4. 인공지능 산업에 대한 투자 강화 및 투자자 참여를 촉진시켜야 합니다. <br/>5. 인공지능 산업의 건전한 발전을 보장하기 위해 인공지능 산업의 법규를 강화해야 합니다.
<br/>

MOSS의 대답은 유창한 중국어로 명확하고 논리적이지만 아직 사실적인 오류나 안정성 등의 문제가 있다는 평가를 받았다.<br/>
재밌는 사실은 MOSS는 중국어보다 영어를 더 잘한다는 것이다.<br/>
중국어 단어는 300억 개를 학습한 반면 영어 단어는 3000억 개나 학습했다고 한다.
종종 프롬프트에 대해 비윤리적이거나 부적절한 대답을 했을 경우, "싫어요"를 클릭하면 그 결과를 반영해 더 나은 응답을 제공한다.<br/>
Chat GPT와 마찬가지로 Python 코드 생성, 해석 기능이 있지만 그림, 음성, 작곡 및 교육과 같은 기능은 아직은 없으며 앞으로 지속적인 연구를 통해 개발할 예정이다.<br/>

<img src="{{site.url}}\images\2023-03-22-gdata33\m.png" alt="m" style="zoom:80%;" />
<br/>

# 메타llama
대화형 AI가 전세계적으로 뜨거워진 가운데 Meta AI에서 매개변수 기반 인공지능 언어 모델 **LLaMA**를 출시했다.   
**LLaMA**는 Large Language Model Meta AI의 약어로 이 모델의 매개변수는 **70억 개에서 650억 개**로 Open AI의 GPT-3가 1750억개인 것에 비하면 10배 이상 작다.
LLaMA는 소규모 기초 모델로서 이런 모델을 교육하는 것은 1) 새로운 접근 방식을 테스트하고 2) 다른 사람의 작업을 검증하며 3) 새로운 사용 사례를 탐색하는 데 훨씬 적은 컴퓨팅 성능과 리소스가 필요하다.
따라서 대규모 언어 모델 공간에서 적절하다고 한다.
또한 기초 모델은 레이블이 지정되지 않은 대량의 데이터 세트를 학습하므로 다양한 작업을 미세 조정하는 데 이상적이다.

LLaMA는 다른 대형 언어 모델과 마찬가지로 일련의 단어를 입력하면 다음 단어를 예측해 텍스트를 생성하는 방식으로 작동한다.
LLaMA는 7B, 13B, 33B 및 65B 매개변수로 사용할 수 있도록 했으며, 33B와 65B는 1조 4천억 개의 토큰으로, 가장 작은 모델인 7B는 1조 개의 토큰으로 훈련되었다.
모델을 훈련할 때는 라틴 및 키릴 문자를 사용하는 언어에 중점을 두어 가장 많이 사용하는 20개의 언어를 선택했다.

LLaMA는 다목적으로 설계되어 연구자들이 코드를 공유함으로써 새로운 접근 방식들을 더 쉽게 테스트할 수 있다. 
또한 모델의 한계를 보여주고 추가적인 연구를 위해 모델 편향과 문제점 등을 평가하는 벤치마크 점수를 해당 논문에서 제공한다.
아래 링크에 논문을 첨부하였다.
<br/>
<br/>
<img src="{{site.url}}\images\2023-03-22-gdata33\LLAMA.jpg" alt="LLAMA" style="zoom: 50%;" />
<br/>
<br/>
[LLaMA 논문 링크](https://arxiv.org/pdf/2302.13971.pdf){: .btn .btn--primary}
<br/>
<br/>

# 일본 도로클라우드
일본 최초로 도로별 자동차의 통행량을 알 수 있는 클라우드 서비스를 개시했다.
[지구를 기쁨으로 채우자]라는 방향을 가진 일본 메타버스 기업 Geo Technologies는 독자적으로 하루 10억 건 이상의 인류 데이터를 바탕으로 '통행량' 데이터를 축적해 서비스를 제공하는 일본 최초 기업이다.
방대한 인류 데이터를 축적하고 필요한 데이터를 추출해 최종적인 서비스를 구현하기까지 다음과 같은 과제가 있었다고 한다.
1. 인류 데이터는 주로 지역 단위로 형성되며, 도로 단위의 통행량을 파악할 수 없고 출발지와 도착지를 포함해 어디로 이동할지 모른다.
2. 데이터의 전달이 필요하여 전달 구조 구축 비용으로 인해 총 개발 비용이 높아진다.
3. 데이터베이스 이동은 인류 데이터 업데이트에도 개발 비용이 든다.








# 싱가포르토지청


<br/>
<hr/>
<br/>
- 출처<br/>
https://kdata.or.kr/kr/board/info_06/boardList.do <br/>
http://www.cbdio.com/BigData/2023-02/21/content_6172004.htm <br/>
https://indiaai.gov.in/article/meta-s-llama-model-outperforms-openai-s-gpt-3 <br/>
https://ai.facebook.com/blog/large-language-model-llama-meta-ai/ <br/>
(사진)https://www.universalcurrentaffairs.com/2023/03/meta-releases-llama-foundation-language.html <br/>
